{"cells":[{"metadata":{},"cell_type":"markdown","source":["# **Stanford Dog Breeds Classification Using Transfer Learning** <br>\n","TeYang<br>\n","Created: 14/12/2019<br>\n","Last update: 14/12/2019<br>\n","\n","<img src = './Pictures/dogbreeds.jpg'>\n","\n","This kernel was created by following the transfer learning article [here](http://towardsdatascience.com/image-detection-from-scratch-in-keras-f314872006c9) written by Rising Odegua.<br>\n","\n","This is my first kernel after taking a deep learning course and I am still trying to understand the concepts and how to tune the parameters of my model. Huge shoutout to the Kaggle team for the website and micro-courses, as well as Jessica Li for sharing the dataset!\n","\n","We will be looking at the Stanford Dogs dataset, which contains around 20,000 images categorized into 120 dog breeds from all over the world. Here, we will be leveraging the power of **transfer learning** by using a pre-trained model to build our **convolutional neural network** for classifying different dog breeds. This allows us to 'transfer' the weights of low-level features that are inherent in most images (e.g., lines, shapes etc) and apply it to the initial layer of our CNN. Doing so saves us the need to train a model from scrach, which can be challenging for those who do not have a 'big' enough dataset or computational resources. \n","\n","\n","The process is as follows:\n","1. [Data Loading and Structure](#Data_loading_structure)\n","2. [Shuffle and Plot Images](#Shuffle_plot)\n","3. [Subset Data](#Subset_data)\n","4. [Encoding Data](#Encoding_data)\n","5. [Preparing Train, Validation & Test Data](#Preparing_data)\n","6. [Data Augmentation](#Data_augmentation)\n","7. [Model Building](#Model_building)\n","8. [Train Model](#Train_model)    \n","9. [Accuracy and Loss Plots](#Accuracy_loss_plots)\n","10. [Predicting on Test Set](#Predict_test)\n","11. [Model Evaluation Metrics](#Evaluation_metrics)\n","12. [Plot Predictions against Actual Labels](#Plot_predictions)\n","13. [Conclusions](#Conclusions)"]},{"metadata":{},"cell_type":"markdown","source":["<a id='Data_loading_structure'></a>\n","## **1. Data Loading and Structure** ##\n","\n","We start by exploring the dataset to look at the classes/breeds of the dogs to understand more about its structure."]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["# Display the Folders/Classes\n","\n","import numpy as np\n","import pandas as pd \n","import os\n","from shutil import copyfile\n","\n","# copy .py file into the working directory (make sure it has .py suffix)\n","copyfile(src = \"../input/model-evaluation-utils/model_evaluation_utils.py\", dst = \"../working/model_evaluation_utils.py\")\n","\n","print(os.listdir('../input/stanford-dogs-dataset/images/Images/'))\n","dog_classes = os.listdir('../input/stanford-dogs-dataset/images/Images/')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["There are 120 subfolders, each belonging to 1 of the 120 dog breeds. For example, images of the Chow breed are under the subfolder *n02112137-chow*. \n","We then proceed to extract the name of the dog breeds by splitting the folder name."]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":["# Get the dog labels\n","\n","breeds = [breed.split('-',1)[1] for breed in dog_classes] # get labels by splitting the folder name at dash\n","breeds[:10] # view some of the labels"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Then, for each of the images, we get the full path to the image (stored in X), as well as its associated label/class/breed (stored in y). This allows us to load the images easily. "]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Get images full path and their labels\n","\n","from itertools import chain\n","\n","X = []\n","y = []\n","\n","fullpaths = ['../input/stanford-dogs-dataset/images/Images/{}'.format(dog_class) for dog_class in dog_classes]\n","\n","for counter, fullpath in enumerate(fullpaths):\n","    for imgname in os.listdir(fullpath):\n","        X.append([fullpath + '/' + imgname])\n","        y.append(breeds[counter])\n","\n","X = list(chain.from_iterable(X)) # unnest the lists and join together into one list\n","\n","len(X) # number of pictures"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='Shuffle_plot'></a>\n","## **2. Shuffle and Plot Images** ##\n","\n","Here, we shuffle the images and their labels together so that they are not grouped by their breeds."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Random shuffle the images for learning\n","\n","import random\n","\n","# shuffle X and y\n","combined = list(zip(X, y))\n","random.shuffle(combined)\n","\n","X[:], y[:] = zip(*combined)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["And look at a sample batch of the dog images with their associated labels. Notice that the images have different dimensions, so we will have to resize them later before putting them into the model."]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":["# Display random dogs pictures \n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","from matplotlib.image import imread\n","\n","plt.figure(figsize=(30,40))\n","for counter, i in enumerate(random.sample(range(0, len(X)), 25)): # random 25 images\n","    plt.subplot(5, 5, counter+1)\n","    plt.subplots_adjust(hspace=0.1)\n","    filename = X[i]\n","    image = imread(filename)\n","    plt.imshow(image)\n","    plt.title(y[i], fontsize=20)\n","\n","    \n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='Subset_data'></a>\n","## **3. Subset Data** ##\n","\n","The next step is not necessary if you have sufficient computational power. I am running this on a laptop with 8gb of RAM, so everytime the kernel RAM exceeds its memory quota, it shuts down. To deal with that, I subsetted a portion of the dataset. However, this will lower the model performance.\n","\n","*Note: If you are facing this issue as well, proper memory management is highly recommended using the gc.collect() function. This involves deleting the unnecessary variables that you do not need anymore and clearing them from memory.*"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Choose a subset to test code\n","\n","X = X[:4000]\n","y = y[:4000]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='Encoding_data'></a>\n","## **4. Encoding Data** ##\n","\n","It is also very important that we encode the classes/breeds. Here we will use one-hot encoding, so that for each image, there will be 120 columns, with all but 1 column with a value of 0. The only column with a value of 1 is the image's associated class/breed/label."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Convert labels to one-hot encoded labels\n","\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import to_categorical\n","\n","# Label and one-hot encoding y labels\n","le = LabelEncoder()\n","le.fit(y)\n","y_ohe = to_categorical(le.transform(y), len(breeds))\n","y_ohe = np.array(y_ohe)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='Preparing_data'></a>\n","## **5. Preparing Train, Validation & Test Data** ##\n","\n","Now it's time to prepare our training, validation and testing dataset. We do this using the *train_test_split* function from the *sklearn* module. But before that, we load the images to the same dimensions and convert them into an image array, each containing the rgb values of every pixel.\n","\n","*Note: It's important to convert the images into a dimension that is similar to the ones that the pre-trained model is trained on.*"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Prepare train, validation and test data\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.image import img_to_array, load_img\n","\n","img_data = np.array([img_to_array(load_img(img, target_size = (299,299)))\n","                     for img in X]) # load, resize images, and store as array\n","\n","x_train, x_test, y_train, y_test = train_test_split(img_data, y_ohe,\n","                                                   test_size = 0.2,\n","                                                   stratify=np.array(y), # stratify makes sure that proportion of each class in the output is same as the input\n","                                                   random_state = 2) \n","\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n","                                                 test_size = 0.2,\n","                                                 stratify=np.array(y_train),\n","                                                 random_state = 2)\n","\n","print('Training Dataset Size: ', x_train.shape)\n","print('Validation Dataset Size: ', x_val.shape)\n","print('Testing Dataset Size: ', x_test.shape)\n","print('Training Label Size: ', y_train.shape)\n","print('Validation Label Size: ', y_val.shape)\n","print('Testing Label Size: ', y_test.shape)\n","\n","# clear some space from memory\n","import gc\n","del img_data\n","gc.collect()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We can see that we have 2560 training, 640 validation,and 800 testing images. Each image has a 299x299 dimension, with 3 channels, representing the RGB channels.\n","\n","<a id='Data_augmentation'></a>\n","## **6. Data Augmentation** ##\n","We also perform **data augmentation**, especially if we have a small dataset, to give us significantly more diverse data without collecting them. This works by applying some transformation to our images (e.g., rotation, axis flipping) to produce 'new' versions of existing images, thus giving us more data to train with."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Data Augmentation\n","\n","from keras.applications.inception_v3 import preprocess_input\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","batch_size = 32\n","\n","# Create train generator\n","train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, # only use rescale=1./255 if training from scratch\n","                                  rotation_range = 30,\n","                                  width_shift_range = 0.2,\n","                                  height_shift_range = 0.2,\n","                                  horizontal_flip = True) # CHECK\n","\n","train_generator = train_datagen.flow(x_train, y_train,\n","                                     shuffle = False, batch_size = batch_size, seed = 1)\n","\n","# Create validation generator\n","val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) # do not augment validation data\n","\n","val_generator = val_datagen.flow(x_val, y_val,\n","                                shuffle = False, batch_size = batch_size, seed = 1)\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Below is an example of an image that was transformed into 'new' images. The model can then extract features from them and learn that these features are associated with this particular breed of dog."]},{"metadata":{"trusted":true},"cell_type":"code","source":["img_id = 16\n","\n","dog_generator = train_datagen.flow(x_train[img_id:img_id+1], y_train[img_id:img_id+1],\n","                                     shuffle = False, batch_size = batch_size, seed = 1)\n","\n","plt.figure(figsize=(30,20))\n","dogs = [next(dog_generator) for i in range(0,5)]\n","for counter, dog in enumerate(dogs): \n","    plt.subplot(1, 5, counter+1)\n","    plt.imshow(dog[0][0])\n","    #plt.axis('off')\n","    \n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='Model_building'></a>\n","## **7. Model Building** ##\n","\n","The next part is building the model. For this process, we are using Google's Inception V3 model. There are other models available to use in Keras as well. We remove the last layer of the Inception V3 model, and feed the output of it to our own set of layers, ending with a final *Dense* layer to classify or predict which of the 120 breeds the images belong to. We also freeze the initial Inception V3 model as it has already been trained before and compile the model."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Build Model Using Pre-trained Model\n","\n","from keras import models\n","from keras import layers\n","from keras.optimizers import Adam\n","from keras.layers import GlobalAveragePooling2D, Dense, Flatten, Dropout\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.utils.np_utils import to_categorical\n","from keras.utils.vis_utils import plot_model\n","\n","# load InceptionV3 pre-trained model\n","base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (299,299,3))\n","\n","model = models.Sequential()\n","model.add(base_model) # add pre_trained layers\n","model.add(GlobalAveragePooling2D())\n","#model.add(Flatten()) # flatten to 1-D vector to prepare for fully connected layers\n","model.add(Dropout(0.3))\n","model.add(Dense(512, activation = 'relu'))\n","model.add(Dense(512, activation = 'relu'))\n","model.add(Dense(len(breeds), activation = 'softmax'))\n","\n","\n","# Freeze pre-trained layers\n","print('Number of trainable weights before freezing the base layer:', len(model.trainable_weights))\n","model.layers[0].trainable = False\n","print('Number of trainable weights after freezing the base layer:', len(model.trainable_weights))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Compile the Model\n","\n","model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy']) \n","model.summary()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='Train_model'></a>\n","## **8. Train Model** ##\n","\n","It's finally time to train our model. The batch size is the number of images passed to the model for training during every iteration. Therefore, the number of iterations/steps is the number of images divided by the batch size, which constitues one epoch. After each iteration, weights of the nodes will be updated. An epoch ends when the entire dataset has been passed through. The more epoch we have, the more the model will train on the data."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Train Model\n","\n","train_steps_per_epoch = x_train.shape[0] // batch_size\n","val_steps_per_epoch = x_val.shape[0] // batch_size\n","epochs = 20\n","\n","history = model.fit_generator(train_generator,\n","                             steps_per_epoch = train_steps_per_epoch,\n","                             validation_data = val_generator,\n","                             validation_steps = val_steps_per_epoch,\n","                             epochs = epochs, verbose = 1)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='Accuracy_loss_plots'></a>\n","## **9. Accuracy and Loss Plots** ##\n","\n","We made plots of the accuracy and loss for the training and validation data. This gives us an idea of how our model is performing (e.g., underfitting, overfitting)."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Plot Accuracy and Loss \n","\n","f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n","t = f.suptitle('Transfer Learning Performance', fontsize=12)\n","f.subplots_adjust(top=0.85, wspace=0.3)\n","\n","epoch_list = list(range(1,epochs+1))\n","ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n","ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n","ax1.set_xticks(np.arange(0, epochs+1, 5))\n","ax1.set_ylabel('Accuracy Value')\n","ax1.set_xlabel('Epoch')\n","ax1.set_title('Accuracy')\n","l1 = ax1.legend(loc=\"best\")\n","\n","ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n","ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n","ax2.set_xticks(np.arange(0, epochs+1, 5))\n","ax2.set_ylabel('Loss Value')\n","ax2.set_xlabel('Epoch')\n","ax2.set_title('Loss')\n","l2 = ax2.legend(loc=\"best\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='Predict_test'></a>\n","## **10. Predicting on Test Set** ##\n","\n","We then apply our model to a dataset that it has not seen before. This is important, as we want a model that can generalize to other datasets other than what it is trained on. A model that only does well on the training and validation dataset but not on a testing dataset is not a useful one."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Evaluate Model on Test Data\n","\n","x_test1 = x_test / 255. # rescale to 0-1. Divide by 255 as its the max RGB value\n","test_predictions = model.predict(x_test1)\n","\n","# get model predictions\n","predictions = le.classes_[np.argmax(test_predictions,axis=1)] # get labels and reverse back to get the text labels\n","# get target labels\n","target_labels = le.classes_[np.argmax(y_test,axis=1)]\n","\n","# Store in dataframe\n","predict_df = pd.DataFrame({'Target_Labels': target_labels, 'Predictions': predictions})\n","predict_df.head(20)\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We store the correct labels and predictions into a dataframe. The first few cases showed that our model did pretty alright with the predictions.\n","\n","<a id='Evaluation_metrics'></a>\n","## **11. Model Evaluation Metrics** ##\n","\n","Next, we get a measure of how well our model is performing by calculating the accuracy of the predictions against the actual target_labels."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Get accuracy of measure\n","\n","correct = (target_labels == predictions)\n","accuracy = correct.sum() / correct.size\n","print(accuracy)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["A better way is to calculate the precision, recall and F1 score of the classification in addition to accuracy. Looking at the combination of these model evaluation metrics will always give us a better idea of our model performance."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Evaluate Model Performance\n","\n","from model_evaluation_utils import get_metrics\n","\n","get_metrics(true_labels=target_labels,\n","            predicted_labels=predictions)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='Plot_predictions'></a>\n","## **12. Plot Predictions against Actual Labels** ##\n","\n","To better visualize our prediction performance, we plot out a small batch of our testing dataset, together with their actual labels, predictions as well as the probability values that our model predict they are in the category."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Plot Actual vs Predicted Images with Confidence Levels\n","    \n","plt.figure(figsize=(30,40))\n","for counter, i in enumerate(random.sample(range(0, len(y_test)), 30)): # random 30 images\n","    plt.subplot(6, 5, counter+1)\n","    plt.subplots_adjust(hspace=0.6)\n","    actual = str(target_labels[i])\n","    predicted = str(predictions[i])\n","    conf = str(max(test_predictions[i]))\n","    plt.imshow(x_test[i]/255.0)\n","    plt.axis('off')\n","    plt.title('Actual: ' + actual + '\\nPredict: ' + predicted + '\\nConf: ' + conf, fontsize=18)\n","    \n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='Conclusions'></a>\n","## **13. Conclusions** ##\n","\n","I believe that our model did pretty good on the testing dataset with ~86% prediction rate, considering that we only trained it on around 2560 images. This again shows the power of transfer learning. Training on more images will definitely increase the performance. However, I am still trying to figure out a way to store more images in arrays without it showing an error. I am not sure if this is a Kaggle limitation or my computer. Let me know if you have any insights!\n","\n","Machine learning is an iterative process, with lots of trial and error to improve our model. We might try to optimize our models by tuning the parameters of the model such as the number of layers in the network, the number of nodes, the learning rate etc. Go try it out for yourselves--train some models for deep learning!"]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}